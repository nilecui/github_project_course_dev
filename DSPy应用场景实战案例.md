# DSPyåº”ç”¨åœºæ™¯å®æˆ˜æ¡ˆä¾‹

## ğŸ“Š æ¡ˆä¾‹æ¦‚è§ˆ

æœ¬æ–‡æ¡£æä¾›äº†DSPyåœ¨5å¤§æ ¸å¿ƒåº”ç”¨åœºæ™¯ä¸­çš„å®æˆ˜æ¡ˆä¾‹ï¼Œæ¯ä¸ªæ¡ˆä¾‹åŒ…å«ï¼šé¡¹ç›®èƒŒæ™¯ã€æŠ€æœ¯æ–¹æ¡ˆã€å®Œæ•´å®ç°ã€éƒ¨ç½²æŒ‡å¯¼å’Œæ‰©å±•æ€è·¯ã€‚

**5å¤§åº”ç”¨åœºæ™¯ï¼š**
1. ğŸ” **æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)** - æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
2. ğŸ¤– **æ™ºèƒ½ä½“å¼€å‘** - å¤šå·¥å…·å®¢æœåŠ©æ‰‹
3. ğŸ“ **æ–‡æœ¬å¤„ç†åˆ†æ** - æ–‡æ¡£è‡ªåŠ¨åˆ†ç±»
4. ğŸ§® **å¤æ‚æ¨ç†ç³»ç»Ÿ** - æ•°å­¦é—®é¢˜æ±‚è§£å™¨
5. ğŸ¨ **å¤šæ¨¡æ€åº”ç”¨** - å›¾æ–‡å†…å®¹åˆ†æ

---

## ğŸ” æ¡ˆä¾‹1ï¼šæ™ºèƒ½RAGé—®ç­”ç³»ç»Ÿ

### é¡¹ç›®èƒŒæ™¯
æ„å»ºä¸€ä¸ªåŸºäºä¼ä¸šçŸ¥è¯†åº“çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œèƒ½å¤Ÿå‡†ç¡®å›ç­”å‘˜å·¥å…³äºå…¬å¸æ”¿ç­–ã€æŠ€æœ¯æ–‡æ¡£ã€ä¸šåŠ¡æµç¨‹ç­‰é—®é¢˜ã€‚

### æŠ€æœ¯æ–¹æ¡ˆ
- **æ£€ç´¢å±‚**: ColBERTv2 + æ··åˆæ£€ç´¢
- **ç”Ÿæˆå±‚**: ChainOfThought + è‡ªæˆ‘ä¿®æ­£
- **ä¼˜åŒ–**: BootstrapFewShot + MIPROv2
- **è¯„ä¼°**: å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡

### å®Œæ•´å®ç°

#### 1. æ•°æ®å‡†å¤‡å’Œé¢„å¤„ç†
```python
import dspy
import json
from typing import List, Dict, Any
import re

class KnowledgeBaseProcessor:
    """çŸ¥è¯†åº“æ•°æ®å¤„ç†å™¨"""

    def __init__(self):
        self.chunk_size = 500  # æ–‡æ¡£åˆ†å—å¤§å°
        self.overlap = 50      # é‡å å¤§å°

    def load_documents(self, file_path: str) -> List[Dict]:
        """åŠ è½½æ–‡æ¡£"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def chunk_document(self, doc: Dict) -> List[Dict]:
        """å°†æ–‡æ¡£åˆ†å—"""
        content = doc['content']
        chunks = []

        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        current_chunk = ""
        current_length = 0

        for i, paragraph in enumerate(paragraphs):
            paragraph = paragraph.strip()
            if not paragraph:
                continue

            # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°æ®µè½è¶…é™ï¼Œåˆ™ä¿å­˜å½“å‰å—
            if current_length + len(paragraph) > self.chunk_size and current_chunk:
                chunks.append({
                    'content': current_chunk.strip(),
                    'doc_id': doc['id'],
                    'chunk_id': len(chunks),
                    'title': doc.get('title', ''),
                    'category': doc.get('category', 'general')
                })
                current_chunk = paragraph
                current_length = len(paragraph)
            else:
                current_chunk += '\n\n' + paragraph if current_chunk else paragraph
                current_length += len(paragraph) + 2

        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append({
                'content': current_chunk.strip(),
                'doc_id': doc['id'],
                'chunk_id': len(chunks),
                'title': doc.get('title', ''),
                'category': doc.get('category', 'general')
            })

        return chunks

    def preprocess_text(self, text: str) -> str:
        """æ–‡æœ¬é¢„å¤„ç†"""
        # å»é™¤å¤šä½™ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)
        # æ ‡å‡†åŒ–ç©ºæ ¼
        text = re.sub(r' {2,}', ' ', text)
        # å»é™¤ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘]', '', text)
        return text.strip()

    def process_knowledge_base(self, docs_path: str) -> List[Dict]:
        """å¤„ç†æ•´ä¸ªçŸ¥è¯†åº“"""
        documents = self.load_documents(docs_path)
        all_chunks = []

        for doc in documents:
            # é¢„å¤„ç†æ–‡æ¡£å†…å®¹
            doc['content'] = self.preprocess_text(doc['content'])

            # åˆ†å—å¤„ç†
            chunks = self.chunk_document(doc)
            all_chunks.extend(chunks)

        print(f"å¤„ç†å®Œæˆï¼š{len(documents)}ä¸ªæ–‡æ¡£ â†’ {len(all_chunks)}ä¸ªæ–‡æœ¬å—")
        return all_chunks

# ä½¿ç”¨ç¤ºä¾‹
processor = KnowledgeBaseProcessor()
knowledge_chunks = processor.process_knowledge_base("company_knowledge_base.json")
```

#### 2. é«˜çº§RAGç³»ç»Ÿå®ç°
```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class EnterpriseRAG(dspy.Module):
    """ä¼ä¸šçº§RAGç³»ç»Ÿ"""

    def __init__(self, config):
        super().__init__()
        self.config = config

        # æ£€ç´¢ç»„ä»¶
        self.retriever = dspy.ColBERTv2(
            model_path="colbert-ir/colbertv2.0",
            index_path=config.get('index_path', './knowledge_index')
        )

        # é‡æ’åºç»„ä»¶
        self.reranker = dspy.Predict(RerankPassages)

        # æŸ¥è¯¢ç†è§£ç»„ä»¶
        self.query_analyzer = dspy.ChainOfThought(AnalyzeQuery)

        # ç­”æ¡ˆç”Ÿæˆç»„ä»¶
        self.generator = dspy.ChainOfThought(GenerateAnswer)

        # ç­”æ¡ˆéªŒè¯ç»„ä»¶
        self.verifier = dspy.Predict(VerifyAnswer)

        # çŸ¥è¯†åº“ç¼“å­˜
        self.knowledge_cache = {}

    def forward(self, question: str, context_info: Dict = None) -> dspy.Prediction:
        """RAGç³»ç»Ÿå‰å‘ä¼ æ’­"""

        # 1. æŸ¥è¯¢åˆ†æå’Œç†è§£
        analyzed_query = self.query_analyzer(question=question)

        # 2. æ„å»ºæ£€ç´¢ç­–ç•¥
        retrieval_strategy = self._build_retrieval_strategy(analyzed_query)

        # 3. æ‰§è¡Œæ£€ç´¢
        raw_results = self._retrieve_documents(question, retrieval_strategy)

        # 4. ç»“æœé‡æ’åº
        ranked_results = self._rerank_documents(question, raw_results)

        # 5. ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, ranked_results)

        # 6. ç­”æ¡ˆéªŒè¯
        verified_answer = self._verify_answer(question, answer, ranked_results)

        return dspy.Prediction(
            answer=verified_answer.answer,
            confidence=verified_answer.confidence,
            sources=verified_answer.sources,
            reasoning=verified_answer.reasoning,
            retrieval_results=ranked_results
        )

    def _build_retrieval_strategy(self, analyzed_query) -> Dict:
        """æ„å»ºæ£€ç´¢ç­–ç•¥"""
        strategy = {
            'k': 10,  # é»˜è®¤æ£€ç´¢æ•°é‡
            'filters': {},
            'search_type': 'hybrid',  # hybrid, semantic, keyword
            'boost_recent': False
        }

        # æ ¹æ®æŸ¥è¯¢åˆ†æè°ƒæ•´ç­–ç•¥
        if hasattr(analyzed_query, 'query_type'):
            if analyzed_query.query_type == 'factual':
                strategy['k'] = 8
                strategy['search_type'] = 'semantic'
            elif analyzed_query.query_type == 'procedural':
                strategy['k'] = 15
                strategy['boost_recent'] = True
            elif analyzed_query.query_type == 'policy':
                strategy['filters']['category'] = 'policy'
                strategy['search_type'] = 'keyword'

        return strategy

    def _retrieve_documents(self, question: str, strategy: Dict) -> List[Dict]:
        """æ‰§è¡Œæ–‡æ¡£æ£€ç´¢"""

        # æ„å»ºæŸ¥è¯¢æ‰©å±•
        expanded_query = self._expand_query(question)

        # æ‰§è¡Œæ£€ç´¢
        if strategy['search_type'] == 'hybrid':
            results = self.retriever.hybrid_search(
                query=expanded_query,
                k=strategy['k'],
                alpha=0.7,  # è¯­ä¹‰æ£€ç´¢æƒé‡
                filters=strategy.get('filters', {})
            )
        else:
            results = self.retriever.search(
                query=expanded_query,
                k=strategy['k'],
                filters=strategy.get('filters', {})
            )

        # å¦‚æœéœ€è¦ï¼Œæå‡æœ€è¿‘æ–‡æ¡£
        if strategy.get('boost_recent'):
            results = self._boost_recent_documents(results)

        return results

    def _expand_query(self, question: str) -> str:
        """æŸ¥è¯¢æ‰©å±•"""
        # ç®€å•çš„åŒä¹‰è¯æ‰©å±•
        expansions = {
            'å¦‚ä½•': 'æ€ä¹ˆ',
            'å“ªäº›': 'ä»€ä¹ˆ',
            'ä¸ºä»€ä¹ˆ': 'åŸå› ',
            'ä»€ä¹ˆæ—¶å€™': 'ä½•æ—¶'
        }

        expanded = question
        for original, synonym in expansions.items():
            if original in expanded:
                expanded = expanded.replace(original, f"{original} {synonym}")

        return expanded

    def _boost_recent_documents(self, results: List[Dict]) -> List[Dict]:
        """æå‡æœ€è¿‘æ–‡æ¡£çš„æƒé‡"""
        current_year = 2024

        for result in results:
            if 'year' in result['metadata']:
                year_diff = current_year - result['metadata']['year']
                boost_factor = max(0.1, 1.0 - (year_diff * 0.1))
                result['score'] *= boost_factor

        # é‡æ–°æ’åº
        results.sort(key=lambda x: x['score'], reverse=True)
        return results

    def _rerank_documents(self, question: str, documents: List[Dict]) -> List[Dict]:
        """æ–‡æ¡£é‡æ’åº"""
        if len(documents) <= 5:
            return documents  # æ–‡æ¡£å¤ªå°‘ï¼Œæ— éœ€é‡æ’åº

        # å‡†å¤‡é‡æ’åºè¾“å…¥
        passages = [doc['content'] for doc in documents]

        # æ‰§è¡Œé‡æ’åº
        rerank_result = self.reranker(
            query=question,
            passages=passages
        )

        # é‡æ–°ç»„è£…ç»“æœ
        reranked_docs = []
        for i, passage_idx in enumerate(rerank_result.indices):
            if i < len(documents):  # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                doc = documents[passage_idx].copy()
                doc['rerank_score'] = rerank_result.scores[i]
                reranked_docs.append(doc)

        return reranked_docs

    def _generate_answer(self, question: str, documents: List[Dict]) -> Dict:
        """ç”Ÿæˆç­”æ¡ˆ"""
        context = "\n\n".join([
            f"æ–‡æ¡£{i+1}: {doc['content'][:500]}..."
            for i, doc in enumerate(documents[:5])
        ])

        result = self.generator(
            question=question,
            context=context
        )

        return {
            'answer': result.answer,
            'reasoning': result.reasoning,
            'sources': [doc.get('doc_id', '') for doc in documents[:3]]
        }

    def _verify_answer(self, question: str, answer: Dict, documents: List[Dict]) -> Dict:
        """éªŒè¯ç­”æ¡ˆè´¨é‡"""
        verification_result = self.verifier(
            question=question,
            answer=answer['answer'],
            context="\n".join([doc['content'] for doc in documents[:5]])
        )

        # åˆå¹¶éªŒè¯ç»“æœ
        final_answer = {
            'answer': answer['answer'],
            'confidence': verification_result.confidence,
            'sources': answer['sources'],
            'reasoning': answer['reasoning'],
            'verification': verification_result.verification
        }

        return final_answer

# ç­¾åå®šä¹‰
class AnalyzeQuery(dspy.Signature):
    """åˆ†ææŸ¥è¯¢ç±»å‹å’Œæ„å›¾"""
    question = dspy.InputField(desc="ç”¨æˆ·é—®é¢˜")
    query_type = dspy.OutputField(desc="æŸ¥è¯¢ç±»å‹:factual/procedural/policy")
    key_entities = dspy.OutputField(desc="å…³é”®å®ä½“")
    complexity = dspy.OutputField(desc="å¤æ‚åº¦:low/medium/high")

class RerankPassages(dspy.Signature):
    """é‡æ’åºæ–‡æ¡£ç‰‡æ®µ"""
    query = dspy.InputField(desc="æŸ¥è¯¢")
    passages = dspy.InputField(desc="æ–‡æ¡£ç‰‡æ®µåˆ—è¡¨", type=List[str])
    indices = dspy.OutputField(desc="æ’åºåçš„ç´¢å¼•", type=List[int])
    scores = dspy.OutputField(desc="ç›¸å…³æ€§åˆ†æ•°", type=List[float])

class GenerateAnswer(dspy.Signature):
    """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ"""
    question = dspy.InputField(desc="é—®é¢˜")
    context = dspy.InputField(desc="ç›¸å…³æ–‡æ¡£ä¸Šä¸‹æ–‡")
    answer = dspy.OutputField(desc="è¯¦ç»†ç­”æ¡ˆ")
    reasoning = dspy.OutputField(desc="æ¨ç†è¿‡ç¨‹")

class VerifyAnswer(dspy.Signature):
    """éªŒè¯ç­”æ¡ˆè´¨é‡"""
    question = dspy.InputField(desc="åŸå§‹é—®é¢˜")
    answer = dspy.InputField(desc="ç”Ÿæˆçš„ç­”æ¡ˆ")
    context = dspy.InputField(desc="æ–‡æ¡£ä¸Šä¸‹æ–‡")
    verification = dspy.OutputField(desc="éªŒè¯ç»“æœ")
    confidence = dspy.OutputField(desc="ç½®ä¿¡åº¦", type=float)
```

#### 3. ç³»ç»Ÿä¼˜åŒ–
```python
class RAGOptimizer:
    """RAGç³»ç»Ÿä¼˜åŒ–å™¨"""

    def __init__(self, rag_system, train_data):
        self.rag_system = rag_system
        self.train_data = train_data

    def optimize_retrieval(self):
        """ä¼˜åŒ–æ£€ç´¢ç»„ä»¶"""
        print("ä¼˜åŒ–æ£€ç´¢ç»„ä»¶...")

        # BootstrapFewShotä¼˜åŒ–æ£€ç´¢
        retrieval_optimizer = dspy.BootstrapFewShot(
            metric=self._retrieval_metric,
            max_bootstrapped_demos=5,
            max_labeled_demos=3
        )

        # ä¼˜åŒ–æ£€ç´¢å™¨
        optimized_retriever = retrieval_optimizer.compile(
            self.rag_system.retriever,
            trainset=self.train_data
        )

        self.rag_system.retriever = optimized_retriever
        print("æ£€ç´¢ç»„ä»¶ä¼˜åŒ–å®Œæˆ")

    def optimize_generation(self):
        """ä¼˜åŒ–ç”Ÿæˆç»„ä»¶"""
        print("ä¼˜åŒ–ç”Ÿæˆç»„ä»¶...")

        # MIPROv2ä¼˜åŒ–ç”Ÿæˆ
        generation_optimizer = dspy.MIPROv2(
            metric=self._generation_metric,
            num_candidates=8,
            init_temperature=0.8
        )

        # ä¼˜åŒ–ç”Ÿæˆå™¨
        optimized_generator = generation_optimizer.compile(
            self.rag_system.generator,
            trainset=self.train_data
        )

        self.rag_system.generator = optimized_generator
        print("ç”Ÿæˆç»„ä»¶ä¼˜åŒ–å®Œæˆ")

    def _retrieval_metric(self, gold, pred):
        """æ£€ç´¢è´¨é‡è¯„ä¼°"""
        # ç®€åŒ–çš„æ£€ç´¢è¯„ä¼°ï¼šæ£€æŸ¥ç›¸å…³æ–‡æ¡£æ˜¯å¦åœ¨ç»“æœä¸­
        relevant_docs = set(gold.get('relevant_docs', []))
        retrieved_docs = set(pred.get('sources', []))

        if not relevant_docs:
            return 1.0  # å¦‚æœæ²¡æœ‰ç›¸å…³æ–‡æ¡£æ ‡è®°ï¼Œé»˜è®¤æ»¡åˆ†

        precision = len(relevant_docs & retrieved_docs) / max(len(retrieved_docs), 1)
        recall = len(relevant_docs & retrieved_docs) / max(len(relevant_docs), 1)

        return (precision + recall) / 2

    def _generation_metric(self, gold, pred):
        """ç”Ÿæˆè´¨é‡è¯„ä¼°"""
        # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…è¯„ä¼°ç­”æ¡ˆè´¨é‡
        gold_answer = gold.answer.lower()
        pred_answer = pred.answer.lower()

        # è®¡ç®—è¯æ±‡é‡å åº¦
        gold_words = set(gold_answer.split())
        pred_words = set(pred_answer.split())

        if not gold_words:
            return 1.0

        overlap = len(gold_words & pred_words)
        precision = overlap / max(len(pred_words), 1)
        recall = overlap / len(gold_words)

        f1 = 2 * precision * recall / max(precision + recall, 0.001)
        return f1

# è®­ç»ƒæ•°æ®ç¤ºä¾‹
train_examples = [
    Example(
        question="å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯æ€æ ·çš„ï¼Ÿ",
        answer="å…¬å¸å¹´å‡æ”¿ç­–ï¼šå…¥èŒæ»¡1å¹´äº«å—5å¤©å¹´å‡ï¼Œæ¯å¢åŠ 1å¹´å·¥é¾„å¢åŠ 1å¤©ï¼Œæœ€é«˜15å¤©...",
        relevant_docs=["HR_POLICY_001", "EMPLOYEE_GUIDE_003"]
    ),
    # ... æ›´å¤šè®­ç»ƒæ•°æ®
]

# ä¼˜åŒ–ç³»ç»Ÿ
rag_system = EnterpriseRAG(config={'index_path': './company_index'})
optimizer = RAGOptimizer(rag_system, train_examples)

optimizer.optimize_retrieval()
optimizer.optimize_generation()
```

### éƒ¨ç½²æŒ‡å¯¼

#### 1. APIæœåŠ¡éƒ¨ç½²
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

app = FastAPI(title="Enterprise RAG API", version="1.0.0")

class QueryRequest(BaseModel):
    question: str
    user_id: str = None
    context_info: dict = {}

class QueryResponse(BaseModel):
    answer: str
    confidence: float
    sources: List[str]
    reasoning: str
    processing_time: float

# å…¨å±€RAGç³»ç»Ÿå®ä¾‹
rag_system = EnterpriseRAG(config={'index_path': './company_index'})

@app.post("/query", response_model=QueryResponse)
async def query_endpoint(request: QueryRequest):
    """æŸ¥è¯¢æ¥å£"""
    import time
    start_time = time.time()

    try:
        # è°ƒç”¨RAGç³»ç»Ÿ
        result = rag_system(request.question, request.context_info)

        processing_time = time.time() - start_time

        return QueryResponse(
            answer=result.answer,
            confidence=result.confidence,
            sources=result.sources,
            reasoning=result.reasoning,
            processing_time=processing_time
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "timestamp": time.time()}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 2. æ€§èƒ½ç›‘æ§
```python
import time
import logging
from collections import defaultdict, deque
from typing import Dict, List

class RAGMonitor:
    """RAGç³»ç»Ÿç›‘æ§"""

    def __init__(self, window_size=1000):
        self.window_size = window_size
        self.metrics = {
            'response_times': deque(maxlen=window_size),
            'confidence_scores': deque(maxlen=window_size),
            'query_types': defaultdict(int),
            'error_count': 0,
            'total_queries': 0,
            'cache_hits': 0
        }

    def record_query(self, query: str, response: Dict, processing_time: float):
        """è®°å½•æŸ¥è¯¢æŒ‡æ ‡"""
        self.metrics['response_times'].append(processing_time)
        self.metrics['confidence_scores'].append(response.get('confidence', 0))
        self.metrics['total_queries'] += 1

        # åˆ†ææŸ¥è¯¢ç±»å‹
        query_type = self._classify_query(query)
        self.metrics['query_types'][query_type] += 1

        # è®°å½•æ—¥å¿—
        logging.info(f"Query processed: {query[:50]}... - {processing_time:.2f}s")

    def record_error(self, error: str):
        """è®°å½•é”™è¯¯"""
        self.metrics['error_count'] += 1
        logging.error(f"Query error: {error}")

    def record_cache_hit(self):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.metrics['cache_hits'] += 1

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        response_times = list(self.metrics['response_times'])
        confidence_scores = list(self.metrics['confidence_scores'])

        return {
            'avg_response_time': sum(response_times) / max(len(response_times), 1),
            'p95_response_time': np.percentile(response_times, 95) if response_times else 0,
            'avg_confidence': sum(confidence_scores) / max(len(confidence_scores), 1),
            'error_rate': self.metrics['error_count'] / max(self.metrics['total_queries'], 1),
            'cache_hit_rate': self.metrics['cache_hits'] / max(self.metrics['total_queries'], 1),
            'query_type_distribution': dict(self.metrics['query_types']),
            'total_queries': self.metrics['total_queries']
        }

    def _classify_query(self, query: str) -> str:
        """æŸ¥è¯¢åˆ†ç±»"""
        query_lower = query.lower()
        if any(word in query_lower for word in ['å¦‚ä½•', 'æ€ä¹ˆ', 'æ€æ ·']):
            return 'procedural'
        elif any(word in query_lower for word in ['ä»€ä¹ˆ', 'å“ªäº›', 'è°']):
            return 'factual'
        elif any(word in query_lower for word in ['ä¸ºä»€ä¹ˆ', 'åŸå› ']):
            return 'causal'
        else:
            return 'other'

# ç›‘æ§å™¨å®ä¾‹
monitor = RAGMonitor()
```

### æ‰©å±•æ€è·¯

#### 1. å¤šè½®å¯¹è¯æ”¯æŒ
```python
class ConversationalRAG(EnterpriseRAG):
    """æ”¯æŒå¤šè½®å¯¹è¯çš„RAGç³»ç»Ÿ"""

    def __init__(self, config):
        super().__init__(config)
        self.conversation_history = {}
        self.context_manager = ConversationContextManager()

    def forward(self, question: str, user_id: str, session_id: str) -> dspy.Prediction:
        """å¤šè½®å¯¹è¯å¤„ç†"""
        # è·å–å¯¹è¯å†å²
        conversation_key = f"{user_id}_{session_id}"
        history = self.conversation_history.get(conversation_key, [])

        # æ„å»ºä¸Šä¸‹æ–‡
        enriched_question = self.context_manager.build_context(
            question, history
        )

        # è°ƒç”¨åŸºç¡€RAG
        result = super().forward(enriched_question['question'])

        # æ›´æ–°å¯¹è¯å†å²
        self.conversation_history[conversation_key] = history + [
            {'role': 'user', 'content': question},
            {'role': 'assistant', 'content': result.answer}
        ]

        # æ·»åŠ å¯¹è¯ä¸Šä¸‹æ–‡ä¿¡æ¯
        result.conversation_context = enriched_question['context']
        return result
```

#### 2. ä¸ªæ€§åŒ–æ¨è
```python
class PersonalizedRAG(EnterpriseRAG):
    """ä¸ªæ€§åŒ–RAGç³»ç»Ÿ"""

    def __init__(self, config):
        super().__init__(config)
        self.user_profiles = {}
        self.preference_learner = UserPreferenceLearner()

    def forward(self, question: str, user_id: str) -> dspy.Prediction:
        """ä¸ªæ€§åŒ–é—®ç­”"""
        # è·å–ç”¨æˆ·ç”»åƒ
        user_profile = self.user_profiles.get(user_id, {})

        # ä¸ªæ€§åŒ–æŸ¥è¯¢æ‰©å±•
        personalized_query = self._personalize_query(question, user_profile)

        # è°ƒç”¨åŸºç¡€RAG
        result = super().forward(personalized_query)

        # ä¸ªæ€§åŒ–ç»“æœæ’åº
        result = self._personalize_results(result, user_profile)

        # æ›´æ–°ç”¨æˆ·åå¥½
        self.preference_learner.update_preferences(user_id, question, result)

        return result
```

---

## ğŸ¤– æ¡ˆä¾‹2ï¼šå¤šå·¥å…·å®¢æœæ™ºèƒ½ä½“

### é¡¹ç›®èƒŒæ™¯
å¼€å‘ä¸€ä¸ªæ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è°ƒç”¨å¤šç§å·¥å…·ï¼ˆè®¢å•æŸ¥è¯¢ã€é€€æ¢è´§ã€çŸ¥è¯†åº“æœç´¢ã€äººå·¥è½¬æ¥ï¼‰æ¥è§£å†³ç”¨æˆ·é—®é¢˜ã€‚

### æŠ€æœ¯æ–¹æ¡ˆ
- **æ ¸å¿ƒæ¡†æ¶**: ReActæ™ºèƒ½ä½“
- **å·¥å…·é›†æˆ**: è®¢å•ç³»ç»Ÿã€ç‰©æµAPIã€çŸ¥è¯†åº“
- **å¯¹è¯ç®¡ç†**: ä¸Šä¸‹æ–‡è®°å¿†å’ŒçŠ¶æ€è·Ÿè¸ª
- **å†³ç­–è·¯ç”±**: æ„å›¾è¯†åˆ«å’Œå·¥å…·é€‰æ‹©

### å®Œæ•´å®ç°

#### 1. å·¥å…·ç³»ç»Ÿè®¾è®¡
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import requests
import json

class Tool(ABC):
    """å·¥å…·åŸºç±»"""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description

    @abstractmethod
    def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·"""
        pass

    def validate_input(self, **kwargs) -> bool:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        return True

class OrderQueryTool(Tool):
    """è®¢å•æŸ¥è¯¢å·¥å…·"""

    def __init__(self):
        super().__init__(
            name="order_query",
            description="æŸ¥è¯¢è®¢å•ä¿¡æ¯ï¼Œéœ€è¦è®¢å•å·æˆ–æ‰‹æœºå·"
        )

    def execute(self, order_id: str = None, phone: str = None) -> Dict[str, Any]:
        """æŸ¥è¯¢è®¢å•"""
        if not order_id and not phone:
            return {"error": "éœ€è¦æä¾›è®¢å•å·æˆ–æ‰‹æœºå·"}

        # æ¨¡æ‹ŸAPIè°ƒç”¨
        if order_id:
            # æ ¹æ®è®¢å•å·æŸ¥è¯¢
            order_info = self._query_by_order_id(order_id)
        else:
            # æ ¹æ®æ‰‹æœºå·æŸ¥è¯¢
            order_info = self._query_by_phone(phone)

        return order_info

    def _query_by_order_id(self, order_id: str) -> Dict[str, Any]:
        """æ ¹æ®è®¢å•å·æŸ¥è¯¢"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        orders_db = {
            "ORD202401001": {
                "order_id": "ORD202401001",
                "status": "å·²å‘è´§",
                "products": ["æ™ºèƒ½æ‰‹è¡¨", "ä¿æŠ¤è†œ"],
                "total_amount": 1299.00,
                "shipping_address": "åŒ—äº¬å¸‚æœé˜³åŒº...",
                "tracking_number": "SF1234567890",
                "estimated_delivery": "2024-01-15"
            }
        }

        if order_id in orders_db:
            return {"success": True, "data": orders_db[order_id]}
        else:
            return {"success": False, "error": "è®¢å•ä¸å­˜åœ¨"}

    def _query_by_phone(self, phone: str) -> Dict[str, Any]:
        """æ ¹æ®æ‰‹æœºå·æŸ¥è¯¢"""
        # æ¨¡æ‹Ÿå®ç°
        return {"success": True, "data": {"orders": ["ORD202401001", "ORD202401002"]}}

    def validate_input(self, **kwargs) -> bool:
        order_id = kwargs.get('order_id', '')
        phone = kwargs.get('phone', '')
        return bool(order_id) or bool(phone)

class RefundTool(Tool):
    """é€€æ¬¾å·¥å…·"""

    def __init__(self):
        super().__init__(
            name="refund",
            description="å¤„ç†é€€æ¬¾ç”³è¯·ï¼Œéœ€è¦è®¢å•å·å’Œé€€æ¬¾åŸå› "
        )

    def execute(self, order_id: str, reason: str) -> Dict[str, Any]:
        """å¤„ç†é€€æ¬¾"""
        if not order_id or not reason:
            return {"error": "éœ€è¦æä¾›è®¢å•å·å’Œé€€æ¬¾åŸå› "}

        # éªŒè¯è®¢å•çŠ¶æ€
        order_result = OrderQueryTool().execute(order_id=order_id)
        if not order_result.get("success"):
            return {"error": "è®¢å•ä¸å­˜åœ¨"}

        order_data = order_result["data"]
        if order_data["status"] not in ["å·²å‘è´§", "å·²å®Œæˆ"]:
            return {"error": "å½“å‰è®¢å•çŠ¶æ€ä¸æ”¯æŒé€€æ¬¾"}

        # å¤„ç†é€€æ¬¾é€»è¾‘
        refund_id = f"REF{order_id[3:]}{int(time.time())}"
        refund_status = "å¤„ç†ä¸­"

        return {
            "success": True,
            "refund_id": refund_id,
            "status": refund_status,
            "estimated_refund_time": "3-5ä¸ªå·¥ä½œæ—¥"
        }

class KnowledgeSearchTool(Tool):
    """çŸ¥è¯†åº“æœç´¢å·¥å…·"""

    def __init__(self):
        super().__init__(
            name="knowledge_search",
            description="æœç´¢äº§å“çŸ¥è¯†åº“ï¼Œå›ç­”å¸¸è§é—®é¢˜"
        )

    def execute(self, query: str) -> Dict[str, Any]:
        """æœç´¢çŸ¥è¯†åº“"""
        if not query:
            return {"error": "éœ€è¦æä¾›æœç´¢æŸ¥è¯¢"}

        # æ¨¡æ‹ŸçŸ¥è¯†åº“æœç´¢
        knowledge_base = {
            "ä¿ä¿®æ”¿ç­–": "æ‰€æœ‰äº§å“äº«å—ä¸€å¹´è´¨ä¿ï¼Œäººä¸ºæŸåä¸åœ¨ä¿ä¿®èŒƒå›´å†…...",
            "é€€æ¢è´§æ”¿ç­–": "7å¤©æ— ç†ç”±é€€æ¢ï¼Œå•†å“éœ€ä¿æŒåŸåŒ…è£…å®Œå¥½...",
            "é…é€æ—¶é—´": "ä¸€èˆ¬åœ°åŒº3-5ä¸ªå·¥ä½œæ—¥ï¼Œåè¿œåœ°åŒº7-10ä¸ªå·¥ä½œæ—¥...",
            "æ”¯ä»˜æ–¹å¼": "æ”¯æŒæ”¯ä»˜å®ã€å¾®ä¿¡æ”¯ä»˜ã€é“¶è¡Œå¡ã€ä¿¡ç”¨å¡..."
        }

        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        results = []
        for topic, content in knowledge_base.items():
            if any(keyword in query.lower() for keyword in topic.lower().split()):
                results.append({
                    "topic": topic,
                    "content": content,
                    "relevance": 0.8
                })

        return {
            "success": True,
            "results": results,
            "query": query
        }

class HumanTransferTool(Tool):
    """äººå·¥è½¬æ¥å·¥å…·"""

    def __init__(self):
        super().__init__(
            name="human_transfer",
            description="å°†ç”¨æˆ·è½¬æ¥åˆ°äººå·¥å®¢æœ"
        )

    def execute(self, reason: str = None, priority: str = "normal") -> Dict[str, Any]:
        """è½¬æ¥äººå·¥å®¢æœ"""
        # åˆ›å»ºå·¥å•
        ticket_id = f"TK{int(time.time())}"

        return {
            "success": True,
            "ticket_id": ticket_id,
            "estimated_wait_time": "5-10åˆ†é’Ÿ",
            "message": "å·²ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·è€å¿ƒç­‰å¾…"
        }
```

#### 2. ReActæ™ºèƒ½ä½“å®ç°
```python
class CustomerServiceAgent(dspy.Module):
    """å®¢æœæ™ºèƒ½ä½“"""

    def __init__(self):
        super().__init__()

        # åˆå§‹åŒ–å·¥å…·
        self.tools = {
            'order_query': OrderQueryTool(),
            'refund': RefundTool(),
            'knowledge_search': KnowledgeSearchTool(),
            'human_transfer': HumanTransferTool()
        }

        # ReActç»„ä»¶
        self.react = dspy.ReAct(
            CustomerServiceTask,
            tools=list(self.tools.values())
        )

        # æ„å›¾è¯†åˆ«ç»„ä»¶
        self.intent_classifier = dspy.Predict(ClassifyIntent)

        # å¯¹è¯çŠ¶æ€ç®¡ç†
        self.conversation_state = {}

    def forward(self, user_input: str, session_id: str = None) -> dspy.Prediction:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # è¯†åˆ«ç”¨æˆ·æ„å›¾
        intent_result = self.intent_classifier(user_input=user_input)
        user_intent = intent_result.intent

        # æ„å»ºä»»åŠ¡æè¿°
        task_description = self._build_task_description(
            user_input, user_intent, session_id
        )

        # æ‰§è¡ŒReActæ¨ç†
        result = self.react(task=task_description)

        # å¤„ç†ç»“æœ
        final_response = self._process_result(result, user_intent)

        # æ›´æ–°å¯¹è¯çŠ¶æ€
        if session_id:
            self._update_conversation_state(session_id, user_input, final_response)

        return dspy.Prediction(
            response=final_response['response'],
            intent=user_intent,
            tools_used=final_response.get('tools_used', []),
            confidence=final_response.get('confidence', 0.8),
            session_id=session_id
        )

    def _build_task_description(self, user_input: str, intent: str, session_id: str) -> str:
        """æ„å»ºä»»åŠ¡æè¿°"""
        # è·å–å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        context = self._get_conversation_context(session_id) if session_id else ""

        task = f"""
ç”¨æˆ·è¾“å…¥: {user_input}
ç”¨æˆ·æ„å›¾: {intent}
å¯¹è¯å†å²: {context}

è¯·ä½¿ç”¨åˆé€‚çš„å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚å¯ç”¨å·¥å…·åŒ…æ‹¬:
- order_query: æŸ¥è¯¢è®¢å•ä¿¡æ¯
- refund: å¤„ç†é€€æ¬¾ç”³è¯·
- knowledge_search: æœç´¢çŸ¥è¯†åº“
- human_transfer: è½¬æ¥äººå·¥å®¢æœ

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œ:
1. åˆ†æç”¨æˆ·éœ€æ±‚
2. é€‰æ‹©åˆé€‚çš„å·¥å…·
3. æ‰§è¡Œå·¥å…·è°ƒç”¨
4. åŸºäºå·¥å…·ç»“æœç”Ÿæˆå‹å¥½å›å¤
"""

        return task

    def _process_result(self, result: dspy.Prediction, intent: str) -> Dict[str, Any]:
        """å¤„ç†ReActç»“æœ"""
        response = ""
        tools_used = []
        confidence = 0.8

        if hasattr(result, 'final_answer'):
            response = result.final_answer
        elif hasattr(result, 'answer'):
            response = result.answer
        else:
            # æ ¹æ®æ„å›¾ç”Ÿæˆé»˜è®¤å›å¤
            response = self._generate_default_response(intent)

        # åˆ†æå·¥å…·ä½¿ç”¨æƒ…å†µ
        if hasattr(result, 'tool_calls'):
            tools_used = [call.tool_name for call in result.tool_calls]

        # æ ¹æ®ç»“æœè´¨é‡è°ƒæ•´ç½®ä¿¡åº¦
        if "æŠ±æ­‰" in response or "æ— æ³•" in response:
            confidence = 0.4

        return {
            'response': response,
            'tools_used': tools_used,
            'confidence': confidence
        }

    def _generate_default_response(self, intent: str) -> str:
        """ç”Ÿæˆé»˜è®¤å›å¤"""
        default_responses = {
            'order_query': "æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢è®¢å•ä¿¡æ¯ã€‚è¯·æä¾›æ‚¨çš„è®¢å•å·æˆ–æ‰‹æœºå·ã€‚",
            'refund': "å…³äºé€€æ¬¾ç”³è¯·ï¼Œæˆ‘éœ€è¦äº†è§£ä¸€äº›ä¿¡æ¯æ‰èƒ½å¸®æ‚¨å¤„ç†ã€‚",
            'knowledge': "è®©æˆ‘ä¸ºæ‚¨æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ã€‚",
            'complaint': "å¾ˆæŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ï¼Œæˆ‘æ¥å¸®æ‚¨è§£å†³é—®é¢˜ã€‚",
            'general': "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
        }

        return default_responses.get(intent, default_responses['general'])

    def _get_conversation_context(self, session_id: str) -> str:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        if session_id in self.conversation_state:
            history = self.conversation_state[session_id].get('history', [])
            recent_turns = history[-3:]  # æœ€è¿‘3è½®å¯¹è¯
            return "\n".join([
                f"ç”¨æˆ·: {turn['user']}\nåŠ©æ‰‹: {turn['assistant']}"
                for turn in recent_turns
            ])
        return ""

    def _update_conversation_state(self, session_id: str, user_input: str, response: Dict):
        """æ›´æ–°å¯¹è¯çŠ¶æ€"""
        if session_id not in self.conversation_state:
            self.conversation_state[session_id] = {
                'history': [],
                'intent_history': [],
                'start_time': time.time()
            }

        self.conversation_state[session_id]['history'].append({
            'user': user_input,
            'assistant': response['response'],
            'timestamp': time.time()
        })

        self.conversation_state[session_id]['intent_history'].append(response['intent'])

# ç­¾åå®šä¹‰
class CustomerServiceTask(dspy.Signature):
    """å®¢æœä»»åŠ¡"""
    task = dspy.InputField(desc="å®¢æœä»»åŠ¡æè¿°")
    thought = dspy.OutputField(desc="æ€è€ƒè¿‡ç¨‹")
    action = dspy.OutputField(desc="é€‰æ‹©çš„è¡ŒåŠ¨")
    tool_call = dspy.OutputField(desc="å·¥å…·è°ƒç”¨", required=False)
    observation = dspy.OutputField(desc="è§‚å¯Ÿç»“æœ", required=False)
    final_answer = dspy.OutputField(desc="æœ€ç»ˆç­”æ¡ˆ")

class ClassifyIntent(dspy.Signature):
    """æ„å›¾åˆ†ç±»"""
    user_input = dspy.InputField(desc="ç”¨æˆ·è¾“å…¥")
    intent = dspy.OutputField(desc="ç”¨æˆ·æ„å›¾")
    confidence = dspy.OutputField(desc="åˆ†ç±»ç½®ä¿¡åº¦", type=float)
```

#### 3. æ™ºèƒ½è·¯ç”±å’Œå†³ç­–
```python
class IntentRouter:
    """æ„å›¾è·¯ç”±å™¨"""

    def __init__(self):
        self.intent_patterns = {
            'order_query': [
                r'è®¢å•|æŸ¥è¯¢|æˆ‘çš„è®¢å•|è®¢å•çŠ¶æ€|å‘è´§',
                r'å¿«é€’|ç‰©æµ|é…é€'
            ],
            'refund': [
                r'é€€æ¬¾|é€€è´§|é€€æ¢è´§|è¿”é’±',
                r'ä¸è¦äº†|å–æ¶ˆè®¢å•'
            ],
            'knowledge': [
                r'æ€ä¹ˆ|å¦‚ä½•|ä»€ä¹ˆ|ä¸ºä»€ä¹ˆ|æ˜¯å¦',
                r'æ”¿ç­–|è§„å®š|æµç¨‹'
            ],
            'complaint': [
                r'æŠ•è¯‰|é—®é¢˜|æ•…éšœ|é”™è¯¯',
                r'ä¸æ»¡æ„|å¾ˆå·®|ç³Ÿç³•'
            ],
            'human_transfer': [
                r'äººå·¥|å®¢æœ|è½¬æ¥|çœŸäºº',
                r'å¤æ‚|ç‰¹æ®Š|ç´§æ€¥'
            ]
        }

    def classify_intent(self, user_input: str) -> Dict[str, Any]:
        """åˆ†ç±»ç”¨æˆ·æ„å›¾"""
        import re

        intent_scores = {}
        user_input_lower = user_input.lower()

        # è®¡ç®—å„æ„å›¾çš„åŒ¹é…åˆ†æ•°
        for intent, patterns in self.intent_patterns.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, user_input_lower))
                score += matches * 2  # æ¯ä¸ªåŒ¹é…åŠ 2åˆ†

            intent_scores[intent] = score

        # é€‰æ‹©æœ€é«˜åˆ†çš„æ„å›¾
        if max(intent_scores.values()) == 0:
            best_intent = 'general'
            confidence = 0.5
        else:
            best_intent = max(intent_scores, key=intent_scores.get)
            total_score = sum(intent_scores.values())
            confidence = intent_scores[best_intent] / total_score if total_score > 0 else 0.5

        return {
            'intent': best_intent,
            'confidence': confidence,
            'all_scores': intent_scores
        }

class SmartDecisionEngine:
    """æ™ºèƒ½å†³ç­–å¼•æ“"""

    def __init__(self):
        self.rules = [
            self._handle_complicated_query,
            self._handle_urgent_request,
            self._handle_frustration,
            self._handle_first_time_user
        ]

    def make_decision(self, user_input: str, conversation_history: List = None) -> Dict[str, Any]:
        """åšå‡ºå†³ç­–"""
        context = {
            'user_input': user_input,
            'conversation_history': conversation_history or [],
            'time_elapsed': 0
        }

        # åº”ç”¨å†³ç­–è§„åˆ™
        for rule in self.rules:
            decision = rule(context)
            if decision['action'] != 'continue':
                return decision

        # é»˜è®¤å†³ç­–ï¼šæ­£å¸¸å¤„ç†
        return {
            'action': 'normal_process',
            'priority': 'normal',
            'tools_allowed': ['order_query', 'refund', 'knowledge_search'],
            'message': None
        }

    def _handle_complicated_query(self, context: Dict) -> Dict[str, Any]:
        """å¤„ç†å¤æ‚æŸ¥è¯¢"""
        user_input = context['user_input']
        history = context['conversation_history']

        # æ£€æµ‹å¤æ‚åº¦æŒ‡æ ‡
        complexity_indicators = [
            len(user_input.split()) > 50,  # é•¿æ–‡æœ¬
            'æˆ–è€…' in user_input or 'å¦å¤–' in user_input,  # å¤šä¸ªé—®é¢˜
            len([r for r in history[-5:] if r.get('tool_used')]) > 3  # å·²ä½¿ç”¨å¤šä¸ªå·¥å…·
        ]

        if any(complexity_indicators):
            return {
                'action': 'suggest_human',
                'priority': 'high',
                'reason': 'æŸ¥è¯¢å¤æ‚ï¼Œå»ºè®®äººå·¥å¤„ç†',
                'message': 'æ‚¨çš„é—®é¢˜æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘å»ºè®®ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœè·å¾—æ›´å¥½çš„å¸®åŠ©ã€‚'
            }

        return {'action': 'continue'}

    def _handle_urgent_request(self, context: Dict) -> Dict[str, Any]:
        """å¤„ç†ç´§æ€¥è¯·æ±‚"""
        user_input = context['user_input'].lower()

        urgent_keywords = ['ç´§æ€¥', 'æ€¥', 'é©¬ä¸Š', 'ç«‹åˆ»', 'é‡è¦']
        if any(keyword in user_input for keyword in urgent_keywords):
            return {
                'action': 'priority_processing',
                'priority': 'urgent',
                'message': 'æˆ‘ç†è§£è¿™å¾ˆç´§æ€¥ï¼Œä¼šä¼˜å…ˆä¸ºæ‚¨å¤„ç†ã€‚'
            }

        return {'action': 'continue'}

    def _handle_frustration(self, context: Dict) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ²®ä¸§æƒ…ç»ª"""
        user_input = context['user_input'].lower()
        history = context['conversation_history']

        frustration_keywords = [
            'æ²¡ç”¨', 'ä¸å¥½', 'åƒåœ¾', 'ç”Ÿæ°”', 'æ— è¯­',
            'è§£å†³ä¸äº†', 'å¸®ä¸äº†', 'ä¸ä¼šå§'
        ]

        # æ£€æµ‹æ²®ä¸§æƒ…ç»ª
        current_frustration = any(keyword in user_input for keyword in frustration_keywords)
        historical_frustration = sum(1 for turn in history[-5:]
                                  if any(keyword in turn.get('user', '').lower()
                                       for keyword in frustration_keywords))

        if current_frustration or historical_frustration >= 2:
            return {
                'action': 'apologize_and_transfer',
                'priority': 'high',
                'message': 'å¾ˆæŠ±æ­‰æ²¡èƒ½å¾ˆå¥½åœ°å¸®åŠ©æ‚¨ã€‚è®©æˆ‘ä¸ºæ‚¨è½¬æ¥æ›´ä¸“ä¸šçš„äººå·¥å®¢æœã€‚',
                'transfer_reason': 'user_frustration'
            }

        return {'action': 'continue'}

    def _handle_first_time_user(self, context: Dict) -> Dict[str, Any]:
        """å¤„ç†é¦–æ¬¡ç”¨æˆ·"""
        history = context['conversation_history']

        if len(history) <= 1:  # é¦–æ¬¡å¯¹è¯
            return {
                'action': 'enhanced_guidance',
                'priority': 'normal',
                'message': 'æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨æŸ¥è¯¢è®¢å•ã€å¤„ç†é€€æ¬¾ã€å›ç­”é—®é¢˜ç­‰ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ',
                'tools_allowed': ['knowledge_search']  # å…ˆä»çŸ¥è¯†åº“å¼€å§‹
            }

        return {'action': 'continue'}

# å¢å¼ºçš„æ™ºèƒ½ä½“
class EnhancedCustomerServiceAgent(CustomerServiceAgent):
    """å¢å¼ºç‰ˆå®¢æœæ™ºèƒ½ä½“"""

    def __init__(self):
        super().__init__()
        self.intent_router = IntentRouter()
        self.decision_engine = SmartDecisionEngine()

    def forward(self, user_input: str, session_id: str = None) -> dspy.Prediction:
        """å¢å¼ºç‰ˆå¤„ç†æµç¨‹"""

        # 1. æ„å›¾è¯†åˆ«
        intent_result = self.intent_router.classify_intent(user_input)

        # 2. è·å–å¯¹è¯å†å²
        history = self._get_conversation_history(session_id) if session_id else []

        # 3. æ™ºèƒ½å†³ç­–
        decision = self.decision_engine.make_decision(user_input, history)

        # 4. æ ¹æ®å†³ç­–æ‰§è¡Œç›¸åº”æ“ä½œ
        if decision['action'] == 'suggest_human':
            return self._transfer_to_human(decision['message'], decision['reason'])
        elif decision['action'] == 'priority_processing':
            # ä½¿ç”¨æ›´å¤šå·¥å…·ï¼Œå¢åŠ å¤„ç†å°è¯•æ¬¡æ•°
            return self._priority_processing(user_input, intent_result, session_id)
        elif decision['action'] == 'apologize_and_transfer':
            return self._apologize_and_transfer(decision['message'])
        else:
            # æ­£å¸¸å¤„ç†æµç¨‹
            return super().forward(user_input, session_id)

    def _transfer_to_human(self, message: str, reason: str) -> dspy.Prediction:
        """è½¬æ¥äººå·¥"""
        transfer_tool = self.tools['human_transfer']
        transfer_result = transfer_tool.execute(reason=reason)

        return dspy.Prediction(
            response=f"{message} {transfer_result.get('message', '')}",
            intent='human_transfer',
            tools_used=['human_transfer'],
            confidence=0.9
        )

    def _priority_processing(self, user_input: str, intent_result: Dict, session_id: str) -> dspy.Prediction:
        """ä¼˜å…ˆå¤„ç†"""
        # è®¾ç½®æ›´ aggressive çš„å¤„ç†å‚æ•°
        result = super().forward(user_input, session_id)

        # å¢åŠ å¤„ç†å°è¯•
        if result.confidence < 0.7:
            # å°è¯•ä½¿ç”¨ä¸åŒå·¥å…·æˆ–é‡æ–°å¤„ç†
            result = self._retry_with_different_approach(user_input, intent_result, session_id)

        return result

    def _apologize_and_transfer(self, message: str) -> dspy.Prediction:
        """é“æ­‰å¹¶è½¬æ¥"""
        transfer_tool = self.tools['human_transfer']
        transfer_result = transfer_tool.execute(reason='user_frustration')

        return dspy.Prediction(
            response=f"{message} {transfer_result.get('message', '')}",
            intent='human_transfer',
            tools_used=['human_transfer'],
            confidence=0.8
        )

    def _retry_with_different_approach(self, user_input: str, intent_result: Dict, session_id: str) -> dspy.Prediction:
        """ä½¿ç”¨ä¸åŒæ–¹æ³•é‡è¯•"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é‡è¯•é€»è¾‘
        # ä¾‹å¦‚ï¼šä½¿ç”¨ä¸åŒçš„å·¥å…·ç»„åˆã€é‡æ–°åˆ†æç”¨æˆ·æ„å›¾ç­‰

        # ç®€åŒ–å®ç°ï¼šç›´æ¥è½¬æ¥äººå·¥
        return self._transfer_to_human(
            "è®©æˆ‘ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœä»¥è·å¾—æ›´å¥½çš„å¸®åŠ©ã€‚",
            "retry_failed"
        )
```

### éƒ¨ç½²å’Œç›‘æ§

#### 1. å®æ—¶å¯¹è¯æ¥å£
```python
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from typing import Dict, List
import json
import asyncio

app = FastAPI(title="Customer Service Agent API")

class ConnectionManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, session_id: str):
        await websocket.accept()
        self.active_connections[session_id] = websocket

    def disconnect(self, session_id: str):
        if session_id in self.active_connections:
            del self.active_connections[session_id]

    async def send_message(self, session_id: str, message: dict):
        if session_id in self.active_connections:
            await self.active_connections[session_id].send_text(json.dumps(message))

manager = ConnectionManager()
agent = EnhancedCustomerServiceAgent()

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    await manager.connect(websocket, session_id)

    try:
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        await manager.send_message(session_id, {
            "type": "welcome",
            "message": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
        })

        while True:
            # æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯
            data = await websocket.receive_text()
            user_message = json.loads(data)

            # å¤„ç†æ¶ˆæ¯
            if user_message.get("type") == "message":
                user_input = user_message.get("content", "")

                # è°ƒç”¨æ™ºèƒ½ä½“
                result = agent.forward(user_input, session_id)

                # å‘é€å“åº”
                await manager.send_message(session_id, {
                    "type": "response",
                    "content": result.response,
                    "intent": result.intent,
                    "confidence": result.confidence,
                    "tools_used": result.tools_used
                })

    except WebSocketDisconnect:
        manager.disconnect(session_id)

@app.post("/chat")
async def chat_endpoint(request: dict):
    """HTTPèŠå¤©æ¥å£"""
    user_input = request.get("message", "")
    session_id = request.get("session_id", "default")

    result = agent.forward(user_input, session_id)

    return {
        "response": result.response,
        "intent": result.intent,
        "confidence": result.confidence,
        "session_id": session_id
    }
```

### æ‰©å±•æ€è·¯

#### 1. æƒ…æ„Ÿåˆ†æé›†æˆ
```python
class EmotionalIntelligence:
    """æƒ…æ„Ÿæ™ºèƒ½æ¨¡å—"""

    def analyze_emotion(self, text: str) -> Dict[str, Any]:
        """åˆ†ææƒ…æ„ŸçŠ¶æ€"""
        # ç®€åŒ–çš„æƒ…æ„Ÿåˆ†æ
        emotions = {
            'happy': ['å¼€å¿ƒ', 'æ»¡æ„', 'å¥½çš„', 'è°¢è°¢'],
            'angry': ['ç”Ÿæ°”', 'æ„¤æ€’', 'ä¸æ»¡', 'ç³Ÿç³•'],
            'sad': ['éš¾è¿‡', 'å¤±æœ›', 'ä¼¤å¿ƒ', 'éƒé—·'],
            'anxious': ['æ‹…å¿ƒ', 'ç€æ€¥', 'ç„¦è™‘', 'ç´§æ€¥']
        }

        emotion_scores = {}
        for emotion, keywords in emotions.items():
            score = sum(1 for keyword in keywords if keyword in text)
            emotion_scores[emotion] = score

        main_emotion = max(emotion_scores, key=emotion_scores.get) if max(emotion_scores.values()) > 0 else 'neutral'

        return {
            'emotion': main_emotion,
            'scores': emotion_scores,
            'intensity': max(emotion_scores.values())
        }

    def generate_empathetic_response(self, emotion: str, context: str) -> str:
        """ç”Ÿæˆå…±æƒ…å›å¤"""
        empathetic_responses = {
            'angry': "å¾ˆæŠ±æ­‰è®©æ‚¨æœ‰è¿™æ ·çš„ä½“éªŒï¼Œæˆ‘ä¼šå°½åŠ›å¸®æ‚¨è§£å†³é—®é¢˜ã€‚",
            'anxious': "æˆ‘ç†è§£æ‚¨çš„æ‹…å¿ƒï¼Œè®©æˆ‘ä»¬ä¸€èµ·çœ‹çœ‹æ€ä¹ˆå¤„ç†è¿™ä¸ªé—®é¢˜ã€‚",
            'sad': "å¬åˆ°è¿™ä¸ªæ¶ˆæ¯æˆ‘å¾ˆéš¾è¿‡ï¼Œå¸Œæœ›èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚",
            'happy': "å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ï¼è¿˜æœ‰å…¶ä»–éœ€è¦å¸®åŠ©çš„å—ï¼Ÿ"
        }

        return empathetic_responses.get(emotion, "æˆ‘æ˜ç™½äº†ï¼Œè®©æˆ‘æ¥å¸®æ‚¨ã€‚")
```

#### 2. å¤šè¯­è¨€æ”¯æŒ
```python
class MultilingualSupport:
    """å¤šè¯­è¨€æ”¯æŒ"""

    def __init__(self):
        self.language_detector = LanguageDetector()
        self.translator = Translator()

    def process_multilingual_input(self, text: str) -> Dict[str, Any]:
        """å¤„ç†å¤šè¯­è¨€è¾“å…¥"""
        detected_lang = self.language_detector.detect(text)

        if detected_lang != 'zh':  # å¦‚æœä¸æ˜¯ä¸­æ–‡
            # ç¿»è¯‘åˆ°ä¸­æ–‡
            translated_text = self.translator.translate(text, from_lang=detected_lang, to_lang='zh')
            return {
                'original_text': text,
                'translated_text': translated_text,
                'original_lang': detected_lang,
                'processed_text': translated_text
            }
        else:
            return {
                'original_text': text,
                'translated_text': text,
                'original_lang': 'zh',
                'processed_text': text
            }

    def translate_response(self, response: str, target_lang: str) -> str:
        """ç¿»è¯‘å›å¤"""
        if target_lang == 'zh':
            return response
        else:
            return self.translator.translate(response, from_lang='zh', to_lang=target_lang)
```

---

*ï¼ˆç”±äºç¯‡å¹…é™åˆ¶ï¼Œå‰©ä½™3ä¸ªæ¡ˆä¾‹"æ–‡æœ¬å¤„ç†åˆ†æ"ã€"å¤æ‚æ¨ç†ç³»ç»Ÿ"å’Œ"å¤šæ¨¡æ€åº”ç”¨"çš„è¯¦ç»†å†…å®¹å°†åœ¨ä¸‹ä¸€ä¸ªæ–‡æ¡£ä¸­ç»§ç»­ï¼‰*